{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query your .pdf's with AzureOpenAI and AzureAI Search with Langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and clean the .pdf document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "doc_reader = PdfReader('./IMF.pdf')\n",
    "\n",
    "raw_text = ''\n",
    "for i, page in enumerate(doc_reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "print(len(raw_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\n",
    "separator= \"\\n\",\n",
    "chunk_size= 1000,\n",
    "chunk_overlap= 200,\n",
    "length_function = len\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize and clean the text for embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def normalize_text(s, sep_token = \"\\n\"):\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "\n",
    "    s = s.replace(\"..\", \".\")\n",
    "    s = s.replace(\"..\", \".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    return s \n",
    "\n",
    "texts = list(map(normalize_text, texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings \n",
    "%pip install --upgrade --quiet  azure-search-documents\n",
    "%pip install --upgrade --quiet  azure-identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"XXX\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"XXX\"\n",
    "#os.environ[\"OPENAI_API_VERSION\"] = \"2022-12-01\"\n",
    "model: str = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = \"\"\n",
    "vector_store_password: str = \"MJR0bptv0TCgtPNg4fnmN7fAm0FJYP1GD61inCij4MAzSeCTnacB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-search-documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Assuming AzureOpenAI is correctly imported or defined\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    # Adjusted to handle a single text input\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "\n",
    "# Generate embeddings for each text in the list\n",
    "embeddings = [generate_embeddings(text, model='text-embedding-ada-002') for text in texts]\n",
    "\n",
    "# If you need to associate these embeddings with their respective texts in a structured form, you can do so. For example:\n",
    "text_embeddings = [{\"text\": text, \"embedding\": embedding} for text, embedding in zip(texts, embeddings)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text_embeddings))\n",
    "print(len(text_embeddings[0][\"embedding\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchableField, ComplexField\n",
    "\n",
    "# Your service details\n",
    "search_service_name = \"ai-search-service-01\"\n",
    "search_index_name = \"imf0x\"\n",
    "api_key = \"XXX\"\n",
    "\n",
    "curl -X PUT https://ai-search-service-01.search.windows.net/indexes/imf0x?api-version=2023-11-01&allowIndexDowntime=true\n",
    "Content-Type: application/json\n",
    "api-key: {{MJR0bptv0TCgtPNg4fnmN7fAm0FJYP1GD61inCij4MAzSeCTnacB}}\n",
    "{\n",
    "    \"name\": \"{{imf0x}}\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"id\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"key\": true,\n",
    "            \"filterable\": true\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"title\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": true,\n",
    "            \"filterable\": true,\n",
    "            \"sortable\": true,\n",
    "            \"retrievable\": true\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"titleVector\",\n",
    "            \"type\": \"Collection(Edm.Single)\",\n",
    "            \"searchable\": true,\n",
    "            \"retrievable\": true,\n",
    "            \"dimensions\": 1536,\n",
    "            \"vectorSearchProfile\": \"my-default-vector-profile\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"content\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": true,\n",
    "            \"retrievable\": true\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"contentVector\",\n",
    "            \"type\": \"Collection(Edm.Single)\",\n",
    "            \"searchable\": true,\n",
    "            \"retrievable\": true,\n",
    "            \"dimensions\": 1536,\n",
    "            \"vectorSearchProfile\": \"my-default-vector-profile\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorSearch\": {\n",
    "        \"algorithms\": [\n",
    "            {\n",
    "                \"name\": \"my-hnsw-config-1\",\n",
    "                \"kind\": \"hnsw\",\n",
    "                \"hnswParameters\": {\n",
    "                    \"m\": 4,\n",
    "                    \"efConstruction\": 400,\n",
    "                    \"efSearch\": 500,\n",
    "                    \"metric\": \"cosine\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"profiles\": [\n",
    "            {\n",
    "                \"name\": \"my-default-vector-profile\",\n",
    "                \"algorithm\": \"my-hnsw-config-1\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_service_name = \"ai-search-service-01\"\n",
    "search_index_name = \"imf0x\"\n",
    "api_key = \"XXX\"\n",
    "\n",
    "search_endpoint = f\"XXX\"\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=search_index_name, credential=AzureKeyCredential(api_key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_embeddings[0][\"text\"])\n",
    "print(text_embeddings[0][\"embedding\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming text_embeddings is structured like this:\n",
    "# text_embeddings = [{\"text\": \"sample text 1\", \"embedding\": [0.1, 0.2, ..., 0.x]}, ...]\n",
    "\n",
    "# Prepare documents for upload\n",
    "documents = []\n",
    "for i, item in enumerate(text_embeddings, start=1):\n",
    "    documents.append({\n",
    "        \"id\": str(i),  # Assigning a unique ID for each document\n",
    "        \"content\": item[\"text\"],  # Your text field\n",
    "        \"contentVector\": item[\"embedding\"]  # Your embedding field; ensure this matches your index configuration\n",
    "    })\n",
    "\n",
    "# Upload documents to the index\n",
    "try:\n",
    "    result = search_client.upload_documents(documents=documents)\n",
    "    print(\"Upload successful\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to upload documents: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
